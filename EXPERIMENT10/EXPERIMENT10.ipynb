{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install scikit-learn pandas matplotlib seaborn\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-AYT-MXkY8QR",
        "outputId": "de65dcb5-c144-4f34-ab9a-2713521b54b9"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.6.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (3.10.0)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.12/dist-packages (0.13.2)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.16.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (3.2.5)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n"
      ],
      "metadata": {
        "id": "IsaGEvjZZBbC"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "CSV_PATH = '/content/data.csv'  # Update with your file path\n",
        "df = pd.read_csv(CSV_PATH)\n",
        "print(df.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oyAFUbesZCmj",
        "outputId": "28da4110-e678-4b3d-e9c4-0c746c9be055"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "         id diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
            "0    842302         M        17.99         10.38          122.80     1001.0   \n",
            "1    842517         M        20.57         17.77          132.90     1326.0   \n",
            "2  84300903         M        19.69         21.25          130.00     1203.0   \n",
            "3  84348301         M        11.42         20.38           77.58      386.1   \n",
            "4  84358402         M        20.29         14.34          135.10     1297.0   \n",
            "\n",
            "   smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
            "0          0.11840           0.27760          0.3001              0.14710   \n",
            "1          0.08474           0.07864          0.0869              0.07017   \n",
            "2          0.10960           0.15990          0.1974              0.12790   \n",
            "3          0.14250           0.28390          0.2414              0.10520   \n",
            "4          0.10030           0.13280          0.1980              0.10430   \n",
            "\n",
            "   ...  texture_worst  perimeter_worst  area_worst  smoothness_worst  \\\n",
            "0  ...          17.33           184.60      2019.0            0.1622   \n",
            "1  ...          23.41           158.80      1956.0            0.1238   \n",
            "2  ...          25.53           152.50      1709.0            0.1444   \n",
            "3  ...          26.50            98.87       567.7            0.2098   \n",
            "4  ...          16.67           152.20      1575.0            0.1374   \n",
            "\n",
            "   compactness_worst  concavity_worst  concave points_worst  symmetry_worst  \\\n",
            "0             0.6656           0.7119                0.2654          0.4601   \n",
            "1             0.1866           0.2416                0.1860          0.2750   \n",
            "2             0.4245           0.4504                0.2430          0.3613   \n",
            "3             0.8663           0.6869                0.2575          0.6638   \n",
            "4             0.2050           0.4000                0.1625          0.2364   \n",
            "\n",
            "   fractal_dimension_worst  Unnamed: 32  \n",
            "0                  0.11890          NaN  \n",
            "1                  0.08902          NaN  \n",
            "2                  0.08758          NaN  \n",
            "3                  0.17300          NaN  \n",
            "4                  0.07678          NaN  \n",
            "\n",
            "[5 rows x 33 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.drop(columns=['id'])\n"
      ],
      "metadata": {
        "id": "ocsSsSBSZIYD"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['diagnosis'] = df['diagnosis'].map({'M': 1, 'B': 0})\n"
      ],
      "metadata": {
        "id": "A4hM4XpfZLbS"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = df.drop(columns=['diagnosis'])\n",
        "y = df['diagnosis']\n"
      ],
      "metadata": {
        "id": "9ov5ESelZNlC"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Missing values in each column:\\n{df.isnull().sum()}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rzm0ox5JZRTy",
        "outputId": "97af3e62-e869-4c3d-93ee-0b772e1baab2"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Missing values in each column:\n",
            "diagnosis                    0\n",
            "radius_mean                  0\n",
            "texture_mean                 0\n",
            "perimeter_mean               0\n",
            "area_mean                    0\n",
            "smoothness_mean              0\n",
            "compactness_mean             0\n",
            "concavity_mean               0\n",
            "concave points_mean          0\n",
            "symmetry_mean                0\n",
            "fractal_dimension_mean       0\n",
            "radius_se                    0\n",
            "texture_se                   0\n",
            "perimeter_se                 0\n",
            "area_se                      0\n",
            "smoothness_se                0\n",
            "compactness_se               0\n",
            "concavity_se                 0\n",
            "concave points_se            0\n",
            "symmetry_se                  0\n",
            "fractal_dimension_se         0\n",
            "radius_worst                 0\n",
            "texture_worst                0\n",
            "perimeter_worst              0\n",
            "area_worst                   0\n",
            "smoothness_worst             0\n",
            "compactness_worst            0\n",
            "concavity_worst              0\n",
            "concave points_worst         0\n",
            "symmetry_worst               0\n",
            "fractal_dimension_worst      0\n",
            "Unnamed: 32                569\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "\n",
        "CSV_PATH = '/content/data.csv'\n",
        "# 1) Load CSV\n",
        "df = pd.read_csv(CSV_PATH)\n",
        "\n",
        "# 2) Drop 'id' column if exists\n",
        "if 'id' in df.columns:\n",
        "    df = df.drop(columns=['id'])\n",
        "\n",
        "# 3) Remove any fully empty columns (like unnamed columns)\n",
        "df = df.dropna(axis=1, how='all')\n",
        "\n",
        "# 4) Convert target to numeric: M=1, B=0\n",
        "df['diagnosis'] = df['diagnosis'].map({'M': 1, 'B': 0})\n",
        "\n",
        "# 5) Separate features and target\n",
        "X = df.drop(columns=['diagnosis'])\n",
        "y = df['diagnosis']\n",
        "\n",
        "# 6) Convert all feature columns to numeric (force any invalid entries to NaN)\n",
        "X = X.apply(pd.to_numeric, errors='coerce')\n",
        "\n",
        "# 7) Fill missing values with column mean\n",
        "X = X.fillna(X.mean())\n",
        "\n",
        "# 8) Check that X and y have rows\n",
        "print(\"Dataset shape after cleaning:\", X.shape, y.shape)\n",
        "if X.shape[0] == 0:\n",
        "    raise ValueError(\"No rows left in dataset after cleaning. Check your CSV for missing values or incorrect formatting.\")\n",
        "\n",
        "# 9) Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "print(f\"Training set size: {X_train.shape[0]}, Test set size: {X_test.shape[0]}\")\n",
        "\n",
        "# 10) Build pipeline: scale + linear SVM\n",
        "pipeline = Pipeline([\n",
        "    ('scaler', StandardScaler()),\n",
        "    ('svc', SVC(kernel='linear', random_state=42))\n",
        "])\n",
        "\n",
        "# 11) Train model\n",
        "pipeline.fit(X_train, y_train)\n",
        "\n",
        "# 12) Predict & evaluate\n",
        "y_pred = pipeline.predict(X_test)\n",
        "print(f\"SVM Accuracy: {accuracy_score(y_test, y_pred)*100:.2f}%\")\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
        "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cObg8RXyZlaK",
        "outputId": "b1a6279a-77fe-45ee-9735-17b4a6a6a261"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset shape after cleaning: (569, 30) (569,)\n",
            "Training set size: 455, Test set size: 114\n",
            "SVM Accuracy: 96.49%\n",
            "Confusion Matrix:\n",
            " [[72  0]\n",
            " [ 4 38]]\n",
            "\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      1.00      0.97        72\n",
            "           1       1.00      0.90      0.95        42\n",
            "\n",
            "    accuracy                           0.96       114\n",
            "   macro avg       0.97      0.95      0.96       114\n",
            "weighted avg       0.97      0.96      0.96       114\n",
            "\n"
          ]
        }
      ]
    }
  ]
}